[cerebrium.deployment]
name = "sesame-csm-streaming"
python_version = "3.11"  # 3.11 has better performance than 3.12
docker_base_image_url = "debian:bookworm-slim"
disable_auth = false
include = ['./main.py', './generator.py', './models.py', 'cerebrium.toml', './requirements.txt']
exclude = ['.*', 'test.py', '__pycache__']

[cerebrium.hardware]
# Increased resources for faster inference
cpu = 4.0
memory = 24.0
# ADA_L4 - Best available on standard plan (24GB VRAM, good performance)
# Alternative: AMPERE_A10 (also 24GB), but L4 is newer architecture
compute = "ADA_L4"

[cerebrium.scaling]
min_replicas = 0
max_replicas = 5
cooldown = 300
replica_concurrency = 1  # Keep at 1 for consistent latency
response_grace_period = 900
scaling_metric = "concurrency_utilization"
scaling_target = 100
scaling_buffer = 0
roll_out_duration_seconds = 0

[cerebrium.dependencies.paths]
pip = "requirements.txt"

[cerebrium.dependencies.apt]
ffmpeg = "latest"
libsndfile1 = "latest"

[cerebrium.runtime]
# Enable CUDA memory optimization
cuda_version = "12.1"
